{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e1a9362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import gc # Garbage Collector\n",
    "import os\n",
    "import sys\n",
    "path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a75074",
   "metadata": {},
   "source": [
    "## LIGHTGBM AISTUDIO BASELINE 0.44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b95181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du script de baseline LightGBM...\n",
      "Préparation finale des données...\n",
      "Séparation des jeux d'entraînement et de test...\n",
      "Création du jeu de validation...\n",
      "Jeu d'entraînement partiel : 2972640 lignes\n",
      "Jeu de validation : 28512 lignes\n",
      "\n",
      "Entraînement du modèle LightGBM avec suivi de la progression...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.796793\n",
      "[200]\tvalid_0's rmse: 0.519378\n",
      "[300]\tvalid_0's rmse: 0.495381\n",
      "[400]\tvalid_0's rmse: 0.491092\n",
      "[500]\tvalid_0's rmse: 0.489253\n",
      "[600]\tvalid_0's rmse: 0.487952\n",
      "[700]\tvalid_0's rmse: 0.487843\n",
      "[800]\tvalid_0's rmse: 0.487726\n",
      "[900]\tvalid_0's rmse: 0.48746\n",
      "[1000]\tvalid_0's rmse: 0.486957\n",
      "[1100]\tvalid_0's rmse: 0.486689\n",
      "Early stopping, best iteration is:\n",
      "[1093]\tvalid_0's rmse: 0.486689\n",
      "\n",
      "Génération des prédictions sur le jeu de test...\n",
      "Meilleure itération trouvée : 1093\n",
      "\n",
      "Fichier 'submission_baseline_lgbm_v2.csv' créé avec succès !\n",
      "              id     sales\n",
      "3001152  3000888  4.475289\n",
      "3002934  3002670  4.197102\n",
      "3004716  3004452  4.262967\n",
      "3006498  3006234  5.296121\n",
      "3008280  3008016  3.086332\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6354d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# ÉTAPE 1: PRÉPARATION FINALE POUR LE MODÈLE\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"Préparation finale des données...\")\n",
    "\n",
    "# !! CORRECTION : On ne supprime pas la colonne 'date' tout de suite !!\n",
    "if 'transactions' in data.columns:\n",
    "    data.drop(columns=['transactions'], inplace=True)\n",
    "\n",
    "# Conversion des colonnes catégorielles\n",
    "categorical_features = [\n",
    "    \"store_nbr\", \"family\", \"city\", \"state\", \"type\", \"cluster\",\n",
    "    \"is_holiday\", \"dayofweek\", \"month\"\n",
    "]\n",
    "for col in categorical_features:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].astype('category')\n",
    "\n",
    "# ==============================================================================\n",
    "# ÉTAPE 2: SÉPARATION DES DONNÉES EN ENTRAÎNEMENT ET TEST\n",
    "# ==============================================================================\n",
    "print(\"Séparation des jeux d'entraînement et de test...\")\n",
    "train_df = data[data['is_train'] == 1].copy()\n",
    "test_df = data[data['is_train'] == 0].copy()\n",
    "\n",
    "# ==============================================================================\n",
    "# ÉTAPE 3 BIS: CRÉATION D'UN JEU DE VALIDATION (MÉTHODE CORRIGÉE)\n",
    "# ==============================================================================\n",
    "print(\"Création du jeu de validation...\")\n",
    "\n",
    "# On utilise la colonne 'date' QUI EXISTE DÉJÀ DANS train_df\n",
    "last_train_date = train_df['date'].max()\n",
    "validation_start_date = last_train_date - pd.DateOffset(days=15)\n",
    "\n",
    "# On crée le masque DIRECTEMENT à partir de train_df. Les longueurs correspondront parfaitement.\n",
    "valid_indices = train_df[train_df['date'] >= validation_start_date].index\n",
    "train_indices = train_df[train_df['date'] < validation_start_date].index\n",
    "\n",
    "# Créer les jeux de données partiels\n",
    "train_part_df = train_df.loc[train_indices]\n",
    "valid_df = train_df.loc[valid_indices]\n",
    "\n",
    "print(f\"Jeu d'entraînement partiel : {train_part_df.shape[0]} lignes\")\n",
    "print(f\"Jeu de validation : {valid_df.shape[0]} lignes\")\n",
    "\n",
    "# ==============================================================================\n",
    "# ÉTAPE 4: DÉFINITION DES FEATURES (X) ET DE LA CIBLE (y)\n",
    "# ==============================================================================\n",
    "\n",
    "# La cible est la colonne 'sales'\n",
    "y_train_part = np.log1p(train_part_df['sales'])\n",
    "y_valid = np.log1p(valid_df['sales'])\n",
    "\n",
    "# Les features sont toutes les autres colonnes utiles\n",
    "# !! CORRECTION : On supprime 'date' et les autres colonnes inutiles ICI !!\n",
    "features = [col for col in train_df.columns if col not in ['id', 'sales', 'is_train', 'date']]\n",
    "\n",
    "X_train_part = train_part_df[features]\n",
    "X_valid = valid_df[features]\n",
    "X_test = test_df[features] # On utilise la même liste de features pour le test\n",
    "\n",
    "# Garder les IDs pour la soumission\n",
    "test_ids = test_df['id'].copy()\n",
    "\n",
    "# Libérer de la mémoire\n",
    "del train_df, test_df, data, train_part_df, valid_df\n",
    "gc.collect()\n",
    "\n",
    "# ==============================================================================\n",
    "# ÉTAPE 5: ENTRAÎNEMENT DU MODÈLE LIGHTGBM (inchangé)\n",
    "# ==============================================================================\n",
    "print(\"\\nEntraînement du modèle LightGBM avec suivi de la progression...\")\n",
    "\n",
    "lgb_params = {\n",
    "    'objective': 'regression_l1', 'metric': 'rmse', 'n_estimators': 2000,\n",
    "    'learning_rate': 0.02, 'feature_fraction': 0.8, 'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'num_leaves': 31,\n",
    "    'verbose': -1, 'n_jobs': -1, 'seed': 42, 'boosting_type': 'gbdt',\n",
    "}\n",
    "\n",
    "model = lgb.LGBMRegressor(**lgb_params)\n",
    "\n",
    "model.fit(X_train_part, y_train_part,\n",
    "          eval_set=[(X_valid, y_valid)],\n",
    "          eval_metric='rmse',\n",
    "          callbacks=[\n",
    "              lgb.log_evaluation(period=100),\n",
    "              lgb.early_stopping(stopping_rounds=100)\n",
    "          ],\n",
    "          categorical_feature=[col for col in categorical_features if col in features])\n",
    "\n",
    "# ==============================================================================\n",
    "# ÉTAPE 6: PRÉDICTION ET CRÉATION DU FICHIER DE SOUMISSION (inchangé)\n",
    "# ==============================================================================\n",
    "print(\"\\nGénération des prédictions sur le jeu de test...\")\n",
    "\n",
    "best_iteration = model.best_iteration_ if model.best_iteration_ else lgb_params['n_estimators']\n",
    "print(f\"Meilleure itération trouvée : {best_iteration}\")\n",
    "\n",
    "predictions_log = model.predict(X_test, num_iteration=best_iteration)\n",
    "predictions = np.expm1(predictions_log)\n",
    "predictions[predictions < 0] = 0\n",
    "\n",
    "submission_df = pd.DataFrame({'id': test_ids, 'sales': predictions})\n",
    "submission_df.to_csv('submission_baseline_lgbm_v2.csv', index=False)\n",
    "\n",
    "print(\"\\nFichier 'submission_baseline_lgbm_v2.csv' créé avec succès !\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41e6481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1771d4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c3c54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93df3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
